{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install readability-lxml\n",
        "!pip install lxml[html_clean]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTduzwVB3ff5",
        "outputId": "e3271f6b-cc50-4be1-8904-db52da1999a3"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: readability-lxml in /usr/local/lib/python3.10/dist-packages (0.8.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from readability-lxml) (5.2.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from readability-lxml) (5.3.0)\n",
            "Requirement already satisfied: cssselect in /usr/local/lib/python3.10/dist-packages (from readability-lxml) (1.2.0)\n",
            "Requirement already satisfied: lxml[html_clean] in /usr/local/lib/python3.10/dist-packages (5.3.0)\n",
            "Requirement already satisfied: lxml-html-clean in /usr/local/lib/python3.10/dist-packages (from lxml[html_clean]) (0.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install readability\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgURTycE8wYm",
        "outputId": "80c20aa1-b4a2-44b7-85dd-61be2a53ade7"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: readability in /usr/local/lib/python3.10/dist-packages (0.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nrclex\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MteC0uT9Etu",
        "outputId": "66146eb9-7f3d-4673-f4fc-91c9760de113"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nrclex in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (from nrclex) (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob->nrclex) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->nrclex) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->nrclex) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->nrclex) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->nrclex) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nrclex import NRCLex\n"
      ],
      "metadata": {
        "id": "NqX_atVQ9INb"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from textblob import TextBlob\n",
        "from readability import Document # Changed import from Readability to Document\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "rfncVNfi25iy"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from textblob import TextBlob\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import nltk\n",
        "from readability import Document\n",
        "from torch.optim import AdamW\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "zrBb0TKvFOmH"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download punkt_tab instead of punkt\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "rH43b0iTL-Tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load and Concatenate BuzzFeed Dataset\n",
        "def load_buzzfeed_data():\n",
        "    # Replace with actual paths to true and fake files\n",
        "    true_data = pd.read_csv(\"/content/BuzzFeed_real_news_content.csv\")\n",
        "    fake_data = pd.read_csv(\"/content/BuzzFeed_fake_news_content.csv\")\n",
        "\n",
        "    true_data['label'] = 1\n",
        "    fake_data['label'] = 0\n",
        "\n",
        "    data = pd.concat([true_data, fake_data], ignore_index=True)\n",
        "    return data"
      ],
      "metadata": {
        "id": "6pqPcfdgMBWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing Text\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = ''.join([char for char in text if char.isalnum() or char.isspace()])\n",
        "    return text"
      ],
      "metadata": {
        "id": "rueRj5oXMFBG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(data):\n",
        "    data['word_count'] = data['text'].apply(lambda x: len(word_tokenize(x)))\n",
        "    data['sentence_count'] = data['text'].apply(lambda x: len(sent_tokenize(x)))\n",
        "    data['sentiment'] = data['text'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "\n",
        "    # Readability\n",
        "    def get_readability_score(text):\n",
        "        try:\n",
        "            r = Document(text)\n",
        "            return r.flesch_kincaid().score\n",
        "        except:\n",
        "            return np.nan\n",
        "\n",
        "    data['readability'] = data['text'].apply(get_readability_score)\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "qF4V1b6pMI6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Dataset Preparation\n",
        "class BuzzFeedDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, features, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.features = features\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "        features = self.features[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'features': torch.tensor(features, dtype=torch.float32),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "aicsJaxKML4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model with fixed classifier input size\n",
        "class RoBERTaWithFeatures(torch.nn.Module):\n",
        "    def __init__(self, base_model, num_features, num_labels=2):\n",
        "        super(RoBERTaWithFeatures, self).__init__()\n",
        "        self.roberta = base_model\n",
        "        # The classifier needs to handle both the RoBERTa output and the additional features\n",
        "        self.classifier = torch.nn.Linear(self.roberta.config.hidden_size + num_features, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, features):\n",
        "        # Get the hidden states from RoBERTa (with output_hidden_states=True)\n",
        "        outputs = self.roberta(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
        "        hidden_states = outputs.hidden_states  # Hidden states include all layers\n",
        "\n",
        "        # The first token ([CLS]) is the pooled output for classification\n",
        "        pooled_output = hidden_states[-1][:, 0, :]  # Take the [CLS] token from the last layer\n",
        "\n",
        "        # Concatenate RoBERTa output with additional features\n",
        "        combined_input = torch.cat((pooled_output, features), dim=1)\n",
        "\n",
        "        # Pass through classifier layer\n",
        "        logits = self.classifier(combined_input)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "Vs3nFYpVMPuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Training Function with Mixed Precision and Gradient Accumulation\n",
        "def train_model(model, train_loader, val_loader, optimizer, epochs, device):\n",
        "    model.to(device)\n",
        "    scaler = GradScaler()  # For mixed precision training\n",
        "    gradient_accumulation_steps = 4  # Adjust this value based on your memory limitations\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        optimizer.zero_grad()  # Zero the gradients at the start of each epoch\n",
        "        for step, batch in enumerate(tqdm(train_loader)):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            features = batch['features'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            with autocast():  # Mixed precision\n",
        "                outputs = model(input_ids, attention_mask=attention_mask, features=features)\n",
        "                loss = torch.nn.CrossEntropyLoss()(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # Accumulate gradients over multiple steps\n",
        "            if (step + 1) % gradient_accumulation_steps == 0:\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "        # Clear GPU cache after each epoch\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        evaluate_model(model, val_loader, device)"
      ],
      "metadata": {
        "id": "VRYjAA1GMTnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Function\n",
        "def evaluate_model(model, val_loader, device):\n",
        "    model.eval()\n",
        "    preds, true_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            features = batch['features'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, features=features)\n",
        "            preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Compute evaluation metrics (Accuracy, F1, Precision, Recall)\n",
        "    acc = accuracy_score(true_labels, preds)\n",
        "    f1 = f1_score(true_labels, preds)\n",
        "    precision = precision_score(true_labels, preds)\n",
        "    recall = recall_score(true_labels, preds)\n",
        "    print(f\"Accuracy: {acc}, F1-Score: {f1}, Precision: {precision}, Recall: {recall}\")"
      ],
      "metadata": {
        "id": "4nWifQ1xMbZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Main Execution\n",
        "def main():\n",
        "    data = load_buzzfeed_data()\n",
        "    data['text'] = data['text'].apply(preprocess_text)\n",
        "    data = extract_features(data)\n",
        "\n",
        "    # Specify feature columns explicitly, excluding 'text'\n",
        "    feature_columns = ['word_count', 'sentence_count', 'sentiment', 'readability']\n",
        "    features = data[feature_columns].values\n",
        "\n",
        "    # Fill NaN values with 0 to ensure numeric conversion works\n",
        "    features = np.nan_to_num(features, nan=0.0).astype(np.float32)\n",
        "    labels = data['label'].values\n",
        "    texts = data['text']\n",
        "\n",
        "    # Train-test split\n",
        "    train_texts, val_texts, train_features, val_features, train_labels, val_labels = train_test_split(\n",
        "        texts, features, labels, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Load tokenizer and model\n",
        "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "    base_model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)\n",
        "\n",
        "    # Load the custom model with additional features\n",
        "    model = RoBERTaWithFeatures(base_model, num_features=len(feature_columns))\n",
        "\n",
        "    # Prepare dataset and dataloaders\n",
        "    train_dataset = BuzzFeedDataset(train_texts.tolist(), train_labels.tolist(), tokenizer, train_features)\n",
        "    val_dataset = BuzzFeedDataset(val_texts.tolist(), val_labels.tolist(), tokenizer, val_features)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=8)\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "    # Train and evaluate\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    train_model(model, train_loader, val_loader, optimizer, epochs=30, device=device)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCdBcyE4FWji",
        "outputId": "23e5a2bc-81ba-4970-a3c1-b7711b95dd9d"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "<ipython-input-110-d43ee08023a6>:109: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # For mixed precision training\n",
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:05<00:00,  3.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 4.651791396893953\n",
            "Accuracy: 0.5135135135135135, F1-Score: 0.6785714285714286, Precision: 0.5135135135135135, Recall: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:02<00:00,  7.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 5.13928764352673\n",
            "Accuracy: 0.5135135135135135, F1-Score: 0.6785714285714286, Precision: 0.5135135135135135, Recall: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:02<00:00,  6.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 4.6013162692910745\n",
            "Accuracy: 0.5675675675675675, F1-Score: 0.7037037037037037, Precision: 0.5428571428571428, Recall: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:02<00:00,  6.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4, Loss: 4.473723025698411\n",
            "Accuracy: 0.5675675675675675, F1-Score: 0.7037037037037037, Precision: 0.5428571428571428, Recall: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:04<00:00,  4.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5, Loss: 3.744517618104031\n",
            "Accuracy: 0.5675675675675675, F1-Score: 0.7037037037037037, Precision: 0.5428571428571428, Recall: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:03<00:00,  5.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Loss: 3.101152954917205\n",
            "Accuracy: 0.5135135135135135, F1-Score: 0.5909090909090909, Precision: 0.52, Recall: 0.6842105263157895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:02<00:00,  6.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7, Loss: 2.675400658657676\n",
            "Accuracy: 0.5675675675675675, F1-Score: 0.5789473684210527, Precision: 0.5789473684210527, Recall: 0.5789473684210527\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:02<00:00,  9.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8, Loss: 2.187959671020508\n",
            "Accuracy: 0.5135135135135135, F1-Score: 0.47058823529411764, Precision: 0.5333333333333333, Recall: 0.42105263157894735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:02<00:00,  8.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Loss: 2.099791363665932\n",
            "Accuracy: 0.4864864864864865, F1-Score: 0.42424242424242425, Precision: 0.5, Recall: 0.3684210526315789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:02<00:00,  7.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 2.1202600378739205\n",
            "Accuracy: 0.5405405405405406, F1-Score: 0.5405405405405406, Precision: 0.5555555555555556, Recall: 0.5263157894736842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:01<00:00, 10.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Loss: 2.0980003821222404\n",
            "Accuracy: 0.5405405405405406, F1-Score: 0.5142857142857142, Precision: 0.5625, Recall: 0.47368421052631576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:01<00:00, 10.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12, Loss: 1.891969509814915\n",
            "Accuracy: 0.5675675675675675, F1-Score: 0.5555555555555556, Precision: 0.5882352941176471, Recall: 0.5263157894736842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:01<00:00,  9.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13, Loss: 1.7649323814793636\n",
            "Accuracy: 0.5945945945945946, F1-Score: 0.6153846153846154, Precision: 0.6, Recall: 0.631578947368421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:01<00:00,  9.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14, Loss: 1.4959173751504797\n",
            "Accuracy: 0.6486486486486487, F1-Score: 0.6666666666666666, Precision: 0.65, Recall: 0.6842105263157895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:02<00:00,  7.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15, Loss: 1.1662890628764504\n",
            "Accuracy: 0.6756756756756757, F1-Score: 0.7391304347826086, Precision: 0.6296296296296297, Recall: 0.8947368421052632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:01<00:00, 10.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16, Loss: 1.1878675975297626\n",
            "Accuracy: 0.6756756756756757, F1-Score: 0.6666666666666666, Precision: 0.7058823529411765, Recall: 0.631578947368421\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:01<00:00, 10.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17, Loss: 0.9940542194404101\n",
            "Accuracy: 0.7027027027027027, F1-Score: 0.7555555555555555, Precision: 0.6538461538461539, Recall: 0.8947368421052632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:01<00:00,  9.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18, Loss: 1.0007388152574237\n",
            "Accuracy: 0.7297297297297297, F1-Score: 0.7619047619047619, Precision: 0.6956521739130435, Recall: 0.8421052631578947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:01<00:00, 10.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19, Loss: 0.730717786048588\n",
            "Accuracy: 0.7297297297297297, F1-Score: 0.7619047619047619, Precision: 0.6956521739130435, Recall: 0.8421052631578947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:02<00:00,  7.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20, Loss: 0.6952916666081077\n",
            "Accuracy: 0.7297297297297297, F1-Score: 0.7727272727272727, Precision: 0.68, Recall: 0.8947368421052632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:02<00:00,  9.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21, Loss: 0.7302259810661015\n",
            "Accuracy: 0.7567567567567568, F1-Score: 0.7804878048780488, Precision: 0.7272727272727273, Recall: 0.8421052631578947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:01<00:00, 10.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22, Loss: 0.6086948662996292\n",
            "Accuracy: 0.7567567567567568, F1-Score: 0.8, Precision: 0.6923076923076923, Recall: 0.9473684210526315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:01<00:00, 10.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23, Loss: 0.57399398951154\n",
            "Accuracy: 0.7567567567567568, F1-Score: 0.8, Precision: 0.6923076923076923, Recall: 0.9473684210526315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:01<00:00, 10.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24, Loss: 0.7994742895427503\n",
            "Accuracy: 0.7567567567567568, F1-Score: 0.7906976744186046, Precision: 0.7083333333333334, Recall: 0.8947368421052632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:02<00:00,  8.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25, Loss: 0.5142795294523239\n",
            "Accuracy: 0.7567567567567568, F1-Score: 0.8, Precision: 0.6923076923076923, Recall: 0.9473684210526315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:02<00:00,  6.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26, Loss: 0.5067117276944613\n",
            "Accuracy: 0.7567567567567568, F1-Score: 0.8, Precision: 0.6923076923076923, Recall: 0.9473684210526315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:02<00:00,  6.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27, Loss: 0.6594159971726569\n",
            "Accuracy: 0.7567567567567568, F1-Score: 0.7804878048780488, Precision: 0.7272727272727273, Recall: 0.8421052631578947\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:02<00:00,  6.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28, Loss: 0.4615225517436078\n",
            "Accuracy: 0.8108108108108109, F1-Score: 0.8372093023255814, Precision: 0.75, Recall: 0.9473684210526315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:03<00:00,  5.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29, Loss: 0.45494740730837774\n",
            "Accuracy: 0.7837837837837838, F1-Score: 0.8181818181818182, Precision: 0.72, Recall: 0.9473684210526315\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/19 [00:00<?, ?it/s]<ipython-input-110-d43ee08023a6>:122: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Mixed precision\n",
            "100%|██████████| 19/19 [00:03<00:00,  5.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30, Loss: 0.44904352567697825\n",
            "Accuracy: 0.7567567567567568, F1-Score: 0.8, Precision: 0.6923076923076923, Recall: 0.9473684210526315\n"
          ]
        }
      ]
    }
  ]
}