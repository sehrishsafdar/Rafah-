{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install readability-lxml\n",
        "!pip install lxml[html_clean]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTduzwVB3ff5",
        "outputId": "6f8c9991-8682-4da8-a96c-d0976e89c9bf"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: readability-lxml in /usr/local/lib/python3.10/dist-packages (0.8.1)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from readability-lxml) (5.2.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from readability-lxml) (5.3.0)\n",
            "Requirement already satisfied: cssselect in /usr/local/lib/python3.10/dist-packages (from readability-lxml) (1.2.0)\n",
            "Requirement already satisfied: lxml[html_clean] in /usr/local/lib/python3.10/dist-packages (5.3.0)\n",
            "Requirement already satisfied: lxml-html-clean in /usr/local/lib/python3.10/dist-packages (from lxml[html_clean]) (0.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install readability\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgURTycE8wYm",
        "outputId": "5ad10d42-63a9-48a4-afaf-f28299ebddc8"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: readability in /usr/local/lib/python3.10/dist-packages (0.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nrclex\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MteC0uT9Etu",
        "outputId": "6db06512-31d6-4a7d-d839-73b60f5ade15"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nrclex in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (from nrclex) (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob->nrclex) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->nrclex) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->nrclex) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->nrclex) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob->nrclex) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nrclex import NRCLex\n"
      ],
      "metadata": {
        "id": "NqX_atVQ9INb"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from textblob import TextBlob\n",
        "from readability import Document # Changed import from Readability to Document\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "rfncVNfi25iy"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from textblob import TextBlob\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import nltk\n",
        "from readability import Document\n",
        "from torch.optim import AdamW\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "zrBb0TKvFOmH"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download punkt_tab instead of punkt\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rH43b0iTL-Tq",
        "outputId": "0962309b-005b-4768-9a62-8f6ed4388d54"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load and Concatenate BuzzFeed Dataset\n",
        "def load_buzzfeed_data():\n",
        "    # Replace with actual paths to true and fake files\n",
        "    true_data = pd.read_csv(\"/content/True.csv\")\n",
        "    fake_data = pd.read_csv(\"/content/Fake.csv\")\n",
        "\n",
        "    true_data['label'] = 1\n",
        "    fake_data['label'] = 0\n",
        "\n",
        "    data = pd.concat([true_data, fake_data], ignore_index=True)\n",
        "    return data"
      ],
      "metadata": {
        "id": "6pqPcfdgMBWR"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing Text\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = ''.join([char for char in text if char.isalnum() or char.isspace()])\n",
        "    return text"
      ],
      "metadata": {
        "id": "rueRj5oXMFBG"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(data):\n",
        "    data['word_count'] = data['text'].apply(lambda x: len(word_tokenize(x)))\n",
        "    data['sentence_count'] = data['text'].apply(lambda x: len(sent_tokenize(x)))\n",
        "    data['sentiment'] = data['text'].apply(lambda x: TextBlob(x).sentiment.polarity)\n",
        "\n",
        "    # Readability\n",
        "    def get_readability_score(text):\n",
        "        try:\n",
        "            r = Document(text)\n",
        "            return r.flesch_kincaid().score\n",
        "        except:\n",
        "            return np.nan\n",
        "\n",
        "    data['readability'] = data['text'].apply(get_readability_score)\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "qF4V1b6pMI6D"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Dataset Preparation\n",
        "class BuzzFeedDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, features, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.features = features\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "        features = self.features[idx]\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].squeeze(0),\n",
        "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
        "            'features': torch.tensor(features, dtype=torch.float32),\n",
        "            'label': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "aicsJaxKML4m"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model with fixed classifier input size\n",
        "class RoBERTaWithFeatures(torch.nn.Module):\n",
        "    def __init__(self, base_model, num_features, num_labels=2):\n",
        "        super(RoBERTaWithFeatures, self).__init__()\n",
        "        self.roberta = base_model\n",
        "        # The classifier needs to handle both the RoBERTa output and the additional features\n",
        "        self.classifier = torch.nn.Linear(self.roberta.config.hidden_size + num_features, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, features):\n",
        "        # Get the hidden states from RoBERTa (with output_hidden_states=True)\n",
        "        outputs = self.roberta(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
        "        hidden_states = outputs.hidden_states  # Hidden states include all layers\n",
        "\n",
        "        # The first token ([CLS]) is the pooled output for classification\n",
        "        pooled_output = hidden_states[-1][:, 0, :]  # Take the [CLS] token from the last layer\n",
        "\n",
        "        # Concatenate RoBERTa output with additional features\n",
        "        combined_input = torch.cat((pooled_output, features), dim=1)\n",
        "\n",
        "        # Pass through classifier layer\n",
        "        logits = self.classifier(combined_input)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "Vs3nFYpVMPuq"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Training Function with Mixed Precision and Gradient Accumulation\n",
        "def train_model(model, train_loader, val_loader, optimizer, epochs, device):\n",
        "    model.to(device)\n",
        "    scaler = GradScaler()  # For mixed precision training\n",
        "    gradient_accumulation_steps = 4  # Adjust this value based on your memory limitations\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        optimizer.zero_grad()  # Zero the gradients at the start of each epoch\n",
        "        for step, batch in enumerate(tqdm(train_loader)):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            features = batch['features'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            with autocast():  # Mixed precision\n",
        "                outputs = model(input_ids, attention_mask=attention_mask, features=features)\n",
        "                loss = torch.nn.CrossEntropyLoss()(outputs, labels)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            # Accumulate gradients over multiple steps\n",
        "            if (step + 1) % gradient_accumulation_steps == 0:\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "        # Clear GPU cache after each epoch\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        evaluate_model(model, val_loader, device)"
      ],
      "metadata": {
        "id": "VRYjAA1GMTnz"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Function\n",
        "def evaluate_model(model, val_loader, device):\n",
        "    model.eval()\n",
        "    preds, true_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            features = batch['features'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, features=features)\n",
        "            preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Compute evaluation metrics (Accuracy, F1, Precision, Recall)\n",
        "    acc = accuracy_score(true_labels, preds)\n",
        "    f1 = f1_score(true_labels, preds)\n",
        "    precision = precision_score(true_labels, preds)\n",
        "    recall = recall_score(true_labels, preds)\n",
        "    print(f\"Accuracy: {acc}, F1-Score: {f1}, Precision: {precision}, Recall: {recall}\")"
      ],
      "metadata": {
        "id": "4nWifQ1xMbZ9"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Main Execution\n",
        "def main():\n",
        "    data = load_buzzfeed_data()\n",
        "    data['text'] = data['text'].apply(preprocess_text)\n",
        "    data = extract_features(data)\n",
        "\n",
        "    # Specify feature columns explicitly, excluding 'text'\n",
        "    feature_columns = ['word_count', 'sentence_count', 'sentiment', 'readability']\n",
        "    features = data[feature_columns].values\n",
        "\n",
        "    # Fill NaN values with 0 to ensure numeric conversion works\n",
        "    features = np.nan_to_num(features, nan=0.0).astype(np.float32)\n",
        "    labels = data['label'].values\n",
        "    texts = data['text']\n",
        "\n",
        "    # Train-test split\n",
        "    train_texts, val_texts, train_features, val_features, train_labels, val_labels = train_test_split(\n",
        "        texts, features, labels, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Load tokenizer and model\n",
        "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "    base_model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)\n",
        "\n",
        "    # Load the custom model with additional features\n",
        "    model = RoBERTaWithFeatures(base_model, num_features=len(feature_columns))\n",
        "\n",
        "    # Prepare dataset and dataloaders\n",
        "    train_dataset = BuzzFeedDataset(train_texts.tolist(), train_labels.tolist(), tokenizer, train_features)\n",
        "    val_dataset = BuzzFeedDataset(val_texts.tolist(), val_labels.tolist(), tokenizer, val_features)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=8)\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
        "\n",
        "    # Train and evaluate\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    train_model(model, train_loader, val_loader, optimizer, epochs=30, device=device)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "UCdBcyE4FWji"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}